{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .envファイルからAWSのプロファイルを取得\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = BedrockChat(model_id=\"anthropic.claude-v2:1\", model_kwargs={\"temperature\": 0})\n",
    "# chat = BedrockChat(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\", model_kwargs={\"temperature\": 0.1}, region_name=\"us-east-1\") # 3は対応できていない?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.invoke([HumanMessage('こんにちは、日本語の慣用表現についての4択問題を出してください')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(service_name='bedrock-runtime', region_name='us-east-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jenre = '日本史'\n",
    "\n",
    "# prompt = 'こんにちは、日本語の慣用表現についての4択問題を出してください'\n",
    "prompt = f'''\\\n",
    "### 指示\n",
    "あなたは有名なクイズ作家兼プログラマーです。与えられたジャンルに関する4択クイズを考えて、指定した形式で出力してください。\n",
    "\n",
    "### 条件\n",
    "・出力内容としては「ジャンル」、「問題」、「選択肢1」、「選択肢2」、「選択肢3」、「選択肢4」、「回答番号」、「解説」にしてください。\n",
    "・「回答番号」は「選択肢n」のように「選択肢」と番号の文字列をつなげたものにしてください。\n",
    "・クイズはWebサイトで出題、回答させることを想定している為、プログラムで扱いやすいJSON形式で返してください。\n",
    "・「回答番号」については偏りがあると回答者が真剣に考えることなく選択する可能性があるため、適度にランダムに選択してください。\n",
    "\n",
    "### 出力(JSON)例\n",
    "{{\n",
    "    \"ジャンル\": \"ことわざ\",\n",
    "    \"問題\": \"「猿も木から落ちる」の意味は何ですか？\",\n",
    "    \"選択肢1\": \"猿は木から降りるのが下手\",\n",
    "    \"選択肢2\": \"熟練した人でも失敗することがある\",\n",
    "    \"選択肢3\": \"木が高ければ高いほど落ちやすい\",\n",
    "    \"選択肢4\": \"猿は木を壊す\",\n",
    "    \"回答番号\": \"選択肢2\",\n",
    "    \"解説\": \"このことわざは、普段猿が木登りが上手であるにも関わらず、時には木から落ちることがあるという事実から来ています。\\\\nそれに喩えて、どんなに技術が高く、経験が豊富な人であっても、時には間違いや失敗を犯すことがあるという意味を込めています。\"\n",
    "}}\n",
    "    \n",
    "### ジャンル\n",
    "{jenre}\n",
    "\n",
    "### 出力(JSON)\n",
    "'''\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "model_id = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "response = client.invoke_model(\n",
    "                modelId=model_id,\n",
    "                body=json.dumps(\n",
    "                    {\n",
    "                        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                        \"max_tokens\": 1024,\n",
    "                        \"messages\": [\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                ),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(response.get('body').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = result[\"usage\"][\"input_tokens\"]\n",
    "output_tokens = result[\"usage\"][\"output_tokens\"]\n",
    "output_list = result.get(\"content\", [])\n",
    "\n",
    "print(\"Invocation details:\")\n",
    "print(f\"- The input length is {input_tokens} tokens.\")\n",
    "print(f\"- The output length is {output_tokens} tokens.\")\n",
    "\n",
    "print(f\"- The model returned {len(output_list)} response(s):\")\n",
    "for output in output_list:\n",
    "    print(output[\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_list[0]['text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
